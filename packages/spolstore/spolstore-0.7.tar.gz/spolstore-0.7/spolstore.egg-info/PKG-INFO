Metadata-Version: 2.1
Name: spolstore
Version: 0.7
Summary: rdflib store using SQLite Fulltext index
Home-page: https://github.com/epoz/spolstore
Author: epoz
Author-email: ep@epoz.org
License: BSD-3-Clause
Project-URL: Documentation, https://github.com/epoz/spolstore/blob/main/README.md
Project-URL: Source, https://github.com/epoz/spolstore
Project-URL: Tracker, https://github.com/epoz/spolstore/issues
Platform: any
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: License :: OSI Approved :: BSD License
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Database :: Database Engines/Servers
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE

# SPOLStore

A Python RDFLib store that stores RDF data on a simple Subject-Predicate-Object-Literal basis, with all literals fulltext indexed using the SQLite FTS5.

## Usage

First install the package, this can be done with:

```shell
pip install spolstore
```

Before you can use it, it needs to be `opened` by specifying where on the filesystem the sqlite database containing the graph is.
To use this as a store in RDFlib, initialize and open a graph:

```python
import rdflib
g = rdflib.Graph("spol")
g.open("/tmp/example.spol")
```

If you do not open a graph first, an exception is thrown when trying to call any methods on it.

Once a graph has been parsed, you can perform fulltext searches using a SPARQL query:

```python
import rdflib
g = rdflib.Graph("spol")
g.open("/tmp/example.spol")
g.parse("http://www.w3.org/People/Berners-Lee/card")
q = """
    PREFIX foaf: <http://xmlns.com/foaf/0.1/>

    SELECT ?s ?p
    WHERE {
            ?s ?p "web workshop" .
    }
"""
for r in g.query(q):
    print(r)
```

### Import an ntriples file from disk

You can also load a .nt file from disk using SPOLStore like so:

```shell
python -m spolstore example.nt example.spol
```

The file can be compressed. The script checks for an extension named .gz, and if so, will uncompress the file when reading.
If you know how many triples there are in the file, you can also specify it on the command line to see the progress.

```shell
python -m spolstore --total=6122281 abiggerfile.nt.gz someotherfile.spol
```

See [here for more Usage](docs.md) and querying as a SQL database directly.

## TODO

This is very much the first working version. Consider it a practical prototype. Probably many bugs...

- Handle languages and data types properly for Literals, in stead of the current dumb dumps


