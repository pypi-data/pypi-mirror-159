Metadata-Version: 2.1
Name: torch-ort-infer
Version: 0.0.1
Summary: Accelerate PyTorch models with ONNX Runtime OpenVINO EP
Home-page: https://github.com/pytorch/ort
Author: torch-ort contributors
License: UNKNOWN
Project-URL: Bug Tracker, https://github.com/pytorch/ort/issues
Platform: UNKNOWN
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
Requires-Dist: onnxruntime-openvino (>=1.12.0)
Requires-Dist: torch (>=1.12)
Provides-Extra: openvino
Requires-Dist: onnxruntime-openvino (>=1.12.0) ; extra == 'openvino'

The torch-ort-inference package uses the PyTorch APIs to accelerate PyTorch models using ONNX Runtime OpenVINO EP.

## Dependencies

The torch-ort-inference package depends on the onnxruntime-openvino package.

## Post-installation step

Once torch-ort-inference is installed, there is a post-installation step:

`python -m torch_ort.configure`







